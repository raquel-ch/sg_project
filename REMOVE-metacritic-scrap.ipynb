{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [\n",
    "'https://www.metacritic.com/music/taylor-swift/taylor-swift',\n",
    "'https://www.metacritic.com/music/1989/taylor-swift', \n",
    "'https://www.metacritic.com/music/fearless/taylor-swift', \n",
    "'https://www.metacritic.com/music/speak-now/taylor-swift', \n",
    "'https://www.metacritic.com/music/red/taylor-swift', \n",
    "'https://www.metacritic.com/music/reputation/taylor-swift', \n",
    "'https://www.metacritic.com/music/lover/taylor-swift',\n",
    "'https://www.metacritic.com/music/folklore/taylor-swift',\n",
    "'https://www.metacritic.com/music/evermore/taylor-swift',\n",
    "'https://www.metacritic.com/music/fearless-taylors-version/taylor-swift',\n",
    "'https://www.metacritic.com/music/red-taylors-version/taylor-swift',\n",
    "'https://www.metacritic.com/music/midnights/taylor-swift',\n",
    "'https://www.metacritic.com/music/speak-now-taylors-version/taylor-swift',\n",
    "'https://www.metacritic.com/music/1989-taylors-version/taylor-swift',\n",
    "'https://www.metacritic.com/music/the-tortured-poets-department/taylor-swift',\n",
    "'https://www.metacritic.com/music/the-tortured-poets-department-the-anthology/taylor-swift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Metacritic reviews\n",
    "def scrape_metacritic_reviews(url, n_critics):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {url} with status code {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract all sources\n",
    "    critic_sources = []\n",
    "    source_div = soup.find_all(\"div\", class_=\"source\")\n",
    "    for source in source_div:\n",
    "        source_name = source.find(\"a\").text.strip() if source.find(\"a\") else \"Source Not Found\"\n",
    "        #print(source_name)\n",
    "        critic_sources.append(str(source_name))\n",
    "    \n",
    "    # Extract all critic scores\n",
    "    critic_scores = []\n",
    "    review_grade_divs = soup.find_all(\"div\", class_=\"review_grade\")\n",
    "    for review_grade in review_grade_divs:\n",
    "        score = review_grade.find(\"div\", class_=\"metascore_w\")\n",
    "        if score:\n",
    "            critic_scores.append(int(score.text.strip()))\n",
    "\n",
    "    # Extract all review bodies\n",
    "    review_bodies = []\n",
    "    review_body_divs = soup.find_all(\"div\", class_=\"review_body\")\n",
    "    for review_body in review_body_divs:\n",
    "        body = review_body.text.strip() if review_body else \"No Review Body\"\n",
    "        review_bodies.append(str(body))\n",
    "\n",
    "    \n",
    "    # only keep the information of the first n_critics (those corresponding to the critics' reviews)\n",
    "    critic_scores = critic_scores[:n_critics]\n",
    "    review_bodies = review_bodies[:n_critics]\n",
    "    # make a new list of tuples (critic_score, review_body)\n",
    "    critic_reviews = list(zip(critic_sources, critic_scores, review_bodies))\n",
    "\n",
    "    return critic_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape album data from Metacritic\n",
    "def scrape_metacritic_album(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {url} with status code {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract album title\n",
    "    title = soup.find(\"h1\").text.strip() if soup.find(\"h1\") else \"Title Not Found\"\n",
    "    print(title)\n",
    "\n",
    "    # Extract Metascore\n",
    "    metascore = soup.find(\"span\", itemprop=\"ratingValue\").text.strip() if soup.find(\"span\", class_=\"metascore_w\") else \"No Metascore\"\n",
    "    #print(metascore)\n",
    "    \n",
    "    n_critics = soup.find(\"span\", itemprop=\"reviewCount\").text.strip() if soup.find(\"span\", itemprop=\"reviewCount\") else \"No Critic Count\"\n",
    "    n_critics = int(n_critics.split()[0])\n",
    "    \n",
    "    # Extract review link from metascore_anchor class\n",
    "    review_link_tag = soup.find(\"a\", class_=\"metascore_anchor\")\n",
    "    review_link = review_link_tag['href'] if review_link_tag and review_link_tag.has_attr('href') else None\n",
    "    if review_link:\n",
    "        review_link = f\"https://www.metacritic.com{review_link}\"\n",
    "        #print(review_link)\n",
    "\n",
    "    reviews = scrape_metacritic_reviews(review_link, n_critics)\n",
    "\n",
    "    # Return the extracted data\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"number of critics\": n_critics,\n",
    "        \"reviews\": reviews,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to save data for each album as CSV\n",
    "def save_album_data_to_csv(data):\n",
    "    # Clean the album title for file naming\n",
    "    title = data[\"title\"].replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "\n",
    "    # Create a DataFrame from the reviews\n",
    "    df = pd.DataFrame(data[\"reviews\"], columns=[\"source\",\"score\", \"review\"])\n",
    "\n",
    "    # Define output directory and file path\n",
    "    output_dir = \"./data/album_reviews\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    csv_path = os.path.join(output_dir, f\"{title}.csv\")\n",
    "\n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved data for album '{data['title']}' to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taylor Swift\n",
      "Saved data for album 'Taylor Swift' to ./data/album_reviews/Taylor_Swift.csv\n",
      "1989\n",
      "Saved data for album '1989' to ./data/album_reviews/1989.csv\n",
      "Fearless\n",
      "Saved data for album 'Fearless' to ./data/album_reviews/Fearless.csv\n",
      "Speak Now\n",
      "Saved data for album 'Speak Now' to ./data/album_reviews/Speak_Now.csv\n",
      "Red\n",
      "Saved data for album 'Red' to ./data/album_reviews/Red.csv\n",
      "reputation\n",
      "Saved data for album 'reputation' to ./data/album_reviews/reputation.csv\n",
      "Lover\n",
      "Saved data for album 'Lover' to ./data/album_reviews/Lover.csv\n",
      "folklore\n",
      "Saved data for album 'folklore' to ./data/album_reviews/folklore.csv\n",
      "evermore\n",
      "Saved data for album 'evermore' to ./data/album_reviews/evermore.csv\n",
      "Fearless (Taylor's Version)\n",
      "Saved data for album 'Fearless (Taylor's Version)' to ./data/album_reviews/Fearless_(Taylor's_Version).csv\n",
      "Red (Taylor's Version)\n",
      "Saved data for album 'Red (Taylor's Version)' to ./data/album_reviews/Red_(Taylor's_Version).csv\n",
      "Midnights\n",
      "Saved data for album 'Midnights' to ./data/album_reviews/Midnights.csv\n",
      "Speak Now (Taylor's Version)\n",
      "Saved data for album 'Speak Now (Taylor's Version)' to ./data/album_reviews/Speak_Now_(Taylor's_Version).csv\n",
      "1989 (Taylor's Version)\n",
      "Saved data for album '1989 (Taylor's Version)' to ./data/album_reviews/1989_(Taylor's_Version).csv\n",
      "THE TORTURED POETS DEPARTMENT\n",
      "Saved data for album 'THE TORTURED POETS DEPARTMENT' to ./data/album_reviews/THE_TORTURED_POETS_DEPARTMENT.csv\n",
      "THE TORTURED POETS DEPARTMENT: THE ANTHOLOGY\n",
      "Saved data for album 'THE TORTURED POETS DEPARTMENT: THE ANTHOLOGY' to ./data/album_reviews/THE_TORTURED_POETS_DEPARTMENT:_THE_ANTHOLOGY.csv\n"
     ]
    }
   ],
   "source": [
    "for link in links:\n",
    "    data = scrape_metacritic_album(link)\n",
    "    save_album_data_to_csv(data)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social_graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
