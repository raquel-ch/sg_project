{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis of the lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same dataframe use to build the network. It has merged songs duplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load de data from .pkl file\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load de data from .pkl file\n",
    "loaded_df = pd.read_pickle(\"ts_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_musical_genre</th>\n",
       "      <th>track_type</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>feature</th>\n",
       "      <th>track_videoclip</th>\n",
       "      <th>videoclip_views</th>\n",
       "      <th>spotify_streams</th>\n",
       "      <th>spotify_global_peak</th>\n",
       "      <th>album</th>\n",
       "      <th>...</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Slut!\" (Taylor's Version) (From The Vault)</td>\n",
       "      <td>Synth Pop</td>\n",
       "      <td>Single</td>\n",
       "      <td>180381</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>239579759</td>\n",
       "      <td>2</td>\n",
       "      <td>[1989 (Taylor's Version) [Deluxe], 1989 (Taylo...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.309, 0.345]</td>\n",
       "      <td>[0.591, 0.629]</td>\n",
       "      <td>[0.412, 0.413]</td>\n",
       "      <td>[0.000199, 7.62e-05]</td>\n",
       "      <td>[0.0608, 0.0603]</td>\n",
       "      <td>[-13.27, -13.178]</td>\n",
       "      <td>[0.0863, 0.055]</td>\n",
       "      <td>[155.875, 77.983]</td>\n",
       "      <td>[0.328, 0.306]</td>\n",
       "      <td>flamingo pink sunrise boulevard clink clink yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...Ready For It?</td>\n",
       "      <td>Electropop</td>\n",
       "      <td>Single</td>\n",
       "      <td>208186</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>350.707.005</td>\n",
       "      <td>695895392</td>\n",
       "      <td>3</td>\n",
       "      <td>reputation</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-6.509</td>\n",
       "      <td>0.136</td>\n",
       "      <td>160.015</td>\n",
       "      <td>0.417</td>\n",
       "      <td>knew killer first time saw wondered many girl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Perfectly Good Heart</td>\n",
       "      <td>Country Pop</td>\n",
       "      <td>B-Side</td>\n",
       "      <td>220146</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>25204096</td>\n",
       "      <td>0</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00349</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-5.726</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>156.092</td>\n",
       "      <td>0.268</td>\n",
       "      <td>would wanna break perfectly good heart would w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Place in this World</td>\n",
       "      <td>Country Pop</td>\n",
       "      <td>B-Side</td>\n",
       "      <td>[202080, 199200]</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>40680546</td>\n",
       "      <td>0</td>\n",
       "      <td>[reputation Stadium Tour Surprise Song Playlis...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0577, 0.051]</td>\n",
       "      <td>[0.573, 0.576]</td>\n",
       "      <td>[0.767, 0.777]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.327, 0.32]</td>\n",
       "      <td>[-2.929, -2.881]</td>\n",
       "      <td>[0.0323, 0.0324]</td>\n",
       "      <td>[114.984, 115.028]</td>\n",
       "      <td>[0.438, 0.428]</td>\n",
       "      <td>dont know want dont ask cause im still trying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afterglow</td>\n",
       "      <td>Pop</td>\n",
       "      <td>B-Side</td>\n",
       "      <td>223293</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>368409481</td>\n",
       "      <td>38</td>\n",
       "      <td>Lover</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-8.746</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>111.011</td>\n",
       "      <td>0.399</td>\n",
       "      <td>blew thing proportion youre blue put jail some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    track_name track_musical_genre track_type  \\\n",
       "0  \"Slut!\" (Taylor's Version) (From The Vault)           Synth Pop     Single   \n",
       "1                             ...Ready For It?          Electropop     Single   \n",
       "2                       A Perfectly Good Heart         Country Pop     B-Side   \n",
       "3                        A Place in this World         Country Pop     B-Side   \n",
       "4                                    Afterglow                 Pop     B-Side   \n",
       "\n",
       "        duration_ms feature track_videoclip videoclip_views spotify_streams  \\\n",
       "0            180381      No              No               0       239579759   \n",
       "1            208186      No             Yes     350.707.005       695895392   \n",
       "2            220146      No              No               0        25204096   \n",
       "3  [202080, 199200]      No              No               0        40680546   \n",
       "4            223293      No              No               0       368409481   \n",
       "\n",
       "  spotify_global_peak                                              album  ...  \\\n",
       "0                   2  [1989 (Taylor's Version) [Deluxe], 1989 (Taylo...  ...   \n",
       "1                   3                                         reputation  ...   \n",
       "2                   0                                       Taylor Swift  ...   \n",
       "3                   0  [reputation Stadium Tour Surprise Song Playlis...  ...   \n",
       "4                  38                                              Lover  ...   \n",
       "\n",
       "      acousticness    danceability          energy      instrumentalness  \\\n",
       "0   [0.309, 0.345]  [0.591, 0.629]  [0.412, 0.413]  [0.000199, 7.62e-05]   \n",
       "1           0.0527           0.613           0.764                   0.0   \n",
       "2          0.00349           0.483           0.751                   0.0   \n",
       "3  [0.0577, 0.051]  [0.573, 0.576]  [0.767, 0.777]                   0.0   \n",
       "4             0.13           0.756           0.449                   0.0   \n",
       "\n",
       "           liveness           loudness       speechiness               tempo  \\\n",
       "0  [0.0608, 0.0603]  [-13.27, -13.178]   [0.0863, 0.055]   [155.875, 77.983]   \n",
       "1             0.197             -6.509             0.136             160.015   \n",
       "2             0.128             -5.726            0.0365             156.092   \n",
       "3     [0.327, 0.32]   [-2.929, -2.881]  [0.0323, 0.0324]  [114.984, 115.028]   \n",
       "4             0.114             -8.746            0.0344             111.011   \n",
       "\n",
       "          valence                                     cleaned_lyrics  \n",
       "0  [0.328, 0.306]  flamingo pink sunrise boulevard clink clink yo...  \n",
       "1           0.417  knew killer first time saw wondered many girl ...  \n",
       "2           0.268  would wanna break perfectly good heart would w...  \n",
       "3  [0.438, 0.428]  dont know want dont ask cause im still trying ...  \n",
       "4           0.399  blew thing proportion youre blue put jail some...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate sentiment given a list of tokens based on the LabMT wordlist\n",
    "def sentiment(tokens, LabMT):\n",
    "    #load the LabMT wordlist from Data_Set_S1.txt\n",
    "    with open(LabMT, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    #remove the first three lines \n",
    "    lines = lines[4:]\n",
    "\n",
    "    #create a dictionary of words and their happiness values\n",
    "    word_dict = {}\n",
    "    for line in lines:\n",
    "        line = line.split('\\t')\n",
    "        word = line[0]\n",
    "        happiness = float(line[2])\n",
    "        word_dict[word] = happiness\n",
    "\n",
    "    #calculate the sentiment of the tokens\n",
    "    sentiment = 0\n",
    "    for token in tokens:\n",
    "        if token in word_dict:\n",
    "            sentiment += word_dict[token]\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the sentiment of the lyrics\n",
    "def sentiment_lyrics(lyrics, LabMT):\n",
    "    #lowercase the lyrics\n",
    "    lyrics = lyrics.lower()\n",
    "    #remove punctuation\n",
    "    lyrics = lyrics.translate(str.maketrans('', '', string.punctuation))\n",
    "    #tokenize the lyrics\n",
    "    tokens = word_tokenize(lyrics)\n",
    "    #lemmatize the tokens\n",
    "    #lemmatizer = WordNetLemmatizer()\n",
    "    #tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    #calculate the sentiment of the tokens\n",
    "    sentiment_score = sentiment(tokens, LabMT)\n",
    "    return sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data_Set_S1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lyrics \u001b[38;5;129;01min\u001b[39;00m loaded_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_lyrics\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(lyrics) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m         sentiments[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43msentiment_lyrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlyrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLabMT\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m, in \u001b[0;36msentiment_lyrics\u001b[0;34m(lyrics, LabMT)\u001b[0m\n\u001b[1;32m      8\u001b[0m tokens \u001b[38;5;241m=\u001b[39m word_tokenize(lyrics)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#lemmatize the tokens\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#lemmatizer = WordNetLemmatizer()\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#tokens = [lemmatizer.lemmatize(token) for token in tokens]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#calculate the sentiment of the tokens\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m sentiment_score \u001b[38;5;241m=\u001b[39m \u001b[43msentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLabMT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sentiment_score\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36msentiment\u001b[0;34m(tokens, LabMT)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentiment\u001b[39m(tokens, LabMT):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#load the LabMT wordlist from Data_Set_S1.txt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mLabMT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m         lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#remove the first three lines \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/master/social_graphs/social_graphs/lib/python3.13/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data_Set_S1.txt'"
     ]
    }
   ],
   "source": [
    "#calculate the sentiment of the lyrics.\n",
    "#Take into account that a song may have a list of lyrics instead of a single string\n",
    "LabMT = 'Data_Set_S1.txt'\n",
    "sentiments = defaultdict(list)\n",
    "for lyrics in loaded_df['track_lyrics']:\n",
    "    if type(lyrics) == str:\n",
    "        sentiments['sentiment'].append(sentiment_lyrics(lyrics, LabMT))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social_graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
